{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e78b018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297db5ff",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9dab6715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she was tired of other things she tried this morning an air or two upon the piano sang a simple song in a sweet but slightly metallic voice and then seating herself by the open window read philips letter well mother said the young student looking up with a shade of impatience i hope thee told the elders that father and i are responsible for the piano and that much as thee loves music thee is never in the room when it is played i heard father tell cousin abner that he was whipped so often for whistling when he was a boy that he was determined to have what compensation he could get now thy ways greatly try me ruth and all thy relations is thy father willing thee should go away to a school of the worlds people i have not asked him ruth replied with a look that might imply that she was one of those determined little bodies who first made up her own mind and then compelled others to make up theirs in accordance with hers mother im going to study medicine margaret bolton almost lost for a moment her habitual placidity\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Assuming 'output_filename' is the desired filename for the output WAV file\n",
    "output_filename = 'long_form_audio/concatenated_output.wav'\n",
    "data=pd.read_csv('../MADHAV_task_1/Task3/metadata_test_clean.tsv', sep='\\t', header=None, names=['path', 'text', 'num','sr'])\n",
    "# List to store audio chunks\n",
    "audio_chunks = []\n",
    "target=\"\"\n",
    "# Iterate over all files in the directory\n",
    "for i in range(10):\n",
    "    file_path = f\"output/audio_noise{i}.wav\"\n",
    "\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(file_path, sr=None)\n",
    "    if(target==\"\"):\n",
    "        target=data['text'][i]\n",
    "    else:\n",
    "        target+=\" \"+data['text'][i]\n",
    "    # Append the audio to the list\n",
    "    audio_chunks.append(audio)\n",
    "\n",
    "# Concatenate all audio chunks\n",
    "concatenated_audio = np.concatenate(audio_chunks)\n",
    "\n",
    "# Save the concatenated audio to a new WAV file\n",
    "sf.write(output_filename, concatenated_audio, samplerate=sr)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f9f10",
   "metadata": {},
   "source": [
    "## Model algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2f2b7139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_using_VAD(input_file, pred, chunk_length_sec=15):\n",
    "    # Load the audio file\n",
    "    audio, sr = librosa.load(input_file, sr=None)\n",
    "    timestamps_df=pred*sr/1000\n",
    "    # Calculate the total duration of the audio in samples\n",
    "    total_samples = len(audio)\n",
    "\n",
    "    # Calculate the chunk length in samples\n",
    "    chunk_length_samples = int(sr * chunk_length_sec)\n",
    "\n",
    "    # Create an array to store audio chunks\n",
    "    audio_chunks = []\n",
    "    split_sec=[]\n",
    "    k=0\n",
    "    index=0\n",
    "    while k+chunk_length_samples<total_samples:\n",
    "        start_sample = k\n",
    "        end_sample = k+chunk_length_samples\n",
    "        nearest_timestamp_index = np.abs(np.array(timestamps_df['end']>start_sample) - end_sample).argmin()\n",
    "        nearest_timestamp_end_sample = int(timestamps_df.loc[nearest_timestamp_index, 'end'])\n",
    "        end_sample = min(end_sample, nearest_timestamp_end_sample)\n",
    "        chunk = audio[start_sample:end_sample]\n",
    "        audio_chunks.append(chunk)\n",
    "        split_sec.append((index, start_sample/sr, end_sample/sr))\n",
    "        k=end_sample\n",
    "        index+=1\n",
    "\n",
    "    last_chunk = audio[k:total_samples]\n",
    "    audio_chunks.append(last_chunk)\n",
    "    split_sec.append((index, k/sr, total_samples/sr))\n",
    "    split_sec=pd.DataFrame(split_sec, columns=['index', 'start', 'end'])\n",
    "    return audio_chunks, split_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "163e176a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1260</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2580</td>\n",
       "      <td>3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3730</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4960</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6170</td>\n",
       "      <td>7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8050</td>\n",
       "      <td>10490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10770</td>\n",
       "      <td>12230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12550</td>\n",
       "      <td>13170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13700</td>\n",
       "      <td>14770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15850</td>\n",
       "      <td>18100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18550</td>\n",
       "      <td>26620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30060</td>\n",
       "      <td>31360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31700</td>\n",
       "      <td>32590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>33470</td>\n",
       "      <td>36840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>37530</td>\n",
       "      <td>39180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>39640</td>\n",
       "      <td>41370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>41650</td>\n",
       "      <td>43600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>44000</td>\n",
       "      <td>44850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>47120</td>\n",
       "      <td>52160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>52500</td>\n",
       "      <td>53690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>55000</td>\n",
       "      <td>57320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>57620</td>\n",
       "      <td>59360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>59710</td>\n",
       "      <td>61140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>61560</td>\n",
       "      <td>66690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>68200</td>\n",
       "      <td>69250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>70410</td>\n",
       "      <td>71760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>72050</td>\n",
       "      <td>72870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>73310</td>\n",
       "      <td>77760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>78070</td>\n",
       "      <td>79290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>79570</td>\n",
       "      <td>80340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>80680</td>\n",
       "      <td>81780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>82090</td>\n",
       "      <td>83120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>83400</td>\n",
       "      <td>85800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>86300</td>\n",
       "      <td>87960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>89050</td>\n",
       "      <td>91460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>91740</td>\n",
       "      <td>93740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>94110</td>\n",
       "      <td>96070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>96350</td>\n",
       "      <td>97770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>98120</td>\n",
       "      <td>105470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>107920</td>\n",
       "      <td>108850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>109490</td>\n",
       "      <td>110420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>111810</td>\n",
       "      <td>113570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>114130</td>\n",
       "      <td>115150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>115450</td>\n",
       "      <td>116630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>117330</td>\n",
       "      <td>118710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>118990</td>\n",
       "      <td>119610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>120290</td>\n",
       "      <td>121190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>121500</td>\n",
       "      <td>124430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     start     end\n",
       "0     1260    2300\n",
       "1     2580    3200\n",
       "2     3730    4680\n",
       "3     4960    5650\n",
       "4     6170    7660\n",
       "5     8050   10490\n",
       "6    10770   12230\n",
       "7    12550   13170\n",
       "8    13700   14770\n",
       "9    15850   18100\n",
       "10   18550   26620\n",
       "11   30060   31360\n",
       "12   31700   32590\n",
       "13   33470   36840\n",
       "14   37530   39180\n",
       "15   39640   41370\n",
       "16   41650   43600\n",
       "17   44000   44850\n",
       "18   47120   52160\n",
       "19   52500   53690\n",
       "20   55000   57320\n",
       "21   57620   59360\n",
       "22   59710   61140\n",
       "23   61560   66690\n",
       "24   68200   69250\n",
       "25   70410   71760\n",
       "26   72050   72870\n",
       "27   73310   77760\n",
       "28   78070   79290\n",
       "29   79570   80340\n",
       "30   80680   81780\n",
       "31   82090   83120\n",
       "32   83400   85800\n",
       "33   86300   87960\n",
       "34   89050   91460\n",
       "35   91740   93740\n",
       "36   94110   96070\n",
       "37   96350   97770\n",
       "38   98120  105470\n",
       "39  107920  108850\n",
       "40  109490  110420\n",
       "41  111810  113570\n",
       "42  114130  115150\n",
       "43  115450  116630\n",
       "44  117330  118710\n",
       "45  118990  119610\n",
       "46  120290  121190\n",
       "47  121500  124430"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fsmnvad import FSMNVad\n",
    "# Specify the input audio file\n",
    "input_file = \"long_form_audio/concatenated_output.wav\"\n",
    "vad = FSMNVad()\n",
    "segments = vad.segments_offline(input_file)\n",
    "df=pd.DataFrame(segments, columns=['start', 'end'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "95c6dd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0: start: 0.0 end: 2.3\n",
      "Chunk 1: start: 2.3 end: 3.2\n",
      "Chunk 2: start: 3.2 end: 4.68\n",
      "Chunk 3: start: 4.68 end: 5.65\n",
      "Chunk 4: start: 5.65 end: 7.66\n",
      "Chunk 5: start: 7.66 end: 10.49\n",
      "Chunk 6: start: 10.49 end: 12.23\n",
      "Chunk 7: start: 12.23 end: 13.17\n",
      "Chunk 8: start: 13.17 end: 14.77\n",
      "Chunk 9: start: 14.77 end: 18.1\n",
      "Chunk 10: start: 18.1 end: 23.1\n",
      "Chunk 11: start: 23.1 end: 26.62\n",
      "Chunk 12: start: 26.62 end: 31.36\n",
      "Chunk 13: start: 31.36 end: 32.59\n",
      "Chunk 14: start: 32.59 end: 36.84\n",
      "Chunk 15: start: 36.84 end: 39.18\n",
      "Chunk 16: start: 39.18 end: 41.37\n",
      "Chunk 17: start: 41.37 end: 43.6\n",
      "Chunk 18: start: 43.6 end: 44.85\n",
      "Chunk 19: start: 44.85 end: 49.85\n",
      "Chunk 20: start: 49.85 end: 52.16\n",
      "Chunk 21: start: 52.16 end: 53.69\n",
      "Chunk 22: start: 53.69 end: 57.32\n",
      "Chunk 23: start: 57.32 end: 59.36\n",
      "Chunk 24: start: 59.36 end: 61.14\n",
      "Chunk 25: start: 61.14 end: 66.14\n",
      "Chunk 26: start: 66.14 end: 66.69\n",
      "Chunk 27: start: 66.69 end: 69.25\n",
      "Chunk 28: start: 69.25 end: 71.76\n",
      "Chunk 29: start: 71.76 end: 72.87\n",
      "Chunk 30: start: 72.87 end: 77.76\n",
      "Chunk 31: start: 77.76 end: 79.29\n",
      "Chunk 32: start: 79.29 end: 80.34\n",
      "Chunk 33: start: 80.34 end: 81.78\n",
      "Chunk 34: start: 81.78 end: 83.12\n",
      "Chunk 35: start: 83.12 end: 85.8\n",
      "Chunk 36: start: 85.8 end: 87.96\n",
      "Chunk 37: start: 87.96 end: 91.46\n",
      "Chunk 38: start: 91.46 end: 93.74\n",
      "Chunk 39: start: 93.74 end: 96.07\n",
      "Chunk 40: start: 96.07 end: 97.77\n",
      "Chunk 41: start: 97.77 end: 102.77\n",
      "Chunk 42: start: 102.77 end: 105.47\n",
      "Chunk 43: start: 105.47 end: 108.85\n",
      "Chunk 44: start: 108.85 end: 110.42\n",
      "Chunk 45: start: 110.42 end: 113.57\n",
      "Chunk 46: start: 113.57 end: 115.15\n",
      "Chunk 47: start: 115.15 end: 116.63\n",
      "Chunk 48: start: 116.63 end: 118.71\n",
      "Chunk 49: start: 118.71 end: 119.61\n",
      "Chunk 50: start: 119.61 end: 124.4523125\n"
     ]
    }
   ],
   "source": [
    "# Split the audio into 15-second chunks with adjustment for the last chunk\n",
    "chunks_array, split_sec = split_audio_using_VAD(input_file, df, 5)\n",
    "\n",
    "# Now, chunks_array contains the audio chunks as numpy arrays\n",
    "for i, chunk in enumerate(chunks_array):\n",
    "    print(f\"Chunk {i}: start: {split_sec['start'][i]} end: {split_sec['end'][i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d813d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q espnet_model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ba387409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Choose English ASR model { run: \"auto\" }\n",
    "\n",
    "lang = 'en'\n",
    "fs = 16000 #@param {type:\"integer\"}\n",
    "tag = 'Shinji Watanabe/spgispeech_asr_train_asr_conformer6_n_fft512_hop_length256_raw_en_unnorm_bpe5000_valid.acc.ave' #@param [\"Shinji Watanabe/spgispeech_asr_train_asr_conformer6_n_fft512_hop_length256_raw_en_unnorm_bpe5000_valid.acc.ave\", \"kamo-naoyuki/librispeech_asr_train_asr_conformer6_n_fft512_hop_length256_raw_en_bpe5000_scheduler_confwarmup_steps40000_optim_conflr0.0025_sp_valid.acc.ave\"] {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "db02d99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using legacy_rel_pos and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,181 WARNING [conformer_encoder.py:139] Using legacy_rel_pos and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,181 WARNING [conformer_encoder.py:139] Using legacy_rel_pos and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,181 WARNING [conformer_encoder.py:139] Using legacy_rel_pos and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,181 WARNING [conformer_encoder.py:139] Using legacy_rel_pos and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,181 WARNING [conformer_encoder.py:139] Using legacy_rel_pos and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,181 WARNING [conformer_encoder.py:139] Using legacy_rel_pos and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,181 WARNING [conformer_encoder.py:139] Using legacy_rel_pos and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,181 WARNING [conformer_encoder.py:139] Using legacy_rel_pos and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,181 WARNING [conformer_encoder.py:139] Using legacy_rel_pos and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,181 WARNING [conformer_encoder.py:139] Using legacy_rel_pos and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,181 WARNING [conformer_encoder.py:139] Using legacy_rel_pos and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,181 WARNING [conformer_encoder.py:139] Using legacy_rel_pos and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,181 WARNING [conformer_encoder.py:139] Using legacy_rel_pos and it will be deprecated in the future.\n",
      "WARNING:root:Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,223 WARNING [conformer_encoder.py:246] Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,223 WARNING [conformer_encoder.py:246] Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,223 WARNING [conformer_encoder.py:246] Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,223 WARNING [conformer_encoder.py:246] Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,223 WARNING [conformer_encoder.py:246] Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,223 WARNING [conformer_encoder.py:246] Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,223 WARNING [conformer_encoder.py:246] Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,223 WARNING [conformer_encoder.py:246] Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,223 WARNING [conformer_encoder.py:246] Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,223 WARNING [conformer_encoder.py:246] Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,223 WARNING [conformer_encoder.py:246] Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,223 WARNING [conformer_encoder.py:246] Using legacy_rel_selfattn and it will be deprecated in the future.\n",
      "2023-12-11 18:13:15,223 WARNING [conformer_encoder.py:246] Using legacy_rel_selfattn and it will be deprecated in the future.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import string\n",
    "from espnet_model_zoo.downloader import ModelDownloader\n",
    "from espnet2.bin.asr_inference import Speech2Text\n",
    "\n",
    "\n",
    "d = ModelDownloader()\n",
    "# It may takes a while to download and build models\n",
    "speech2text = Speech2Text(\n",
    "    **d.download_and_unpack(tag),\n",
    "    device=\"cpu\",\n",
    "    minlenratio=0.0,\n",
    "    maxlenratio=0.0,\n",
    "    ctc_weight=0.3,\n",
    "    beam_size=10,\n",
    "    batch_size=0,\n",
    "    nbest=1\n",
    ")\n",
    "\n",
    "def text_normalizer(text):\n",
    "    text = text.upper()\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "641112e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16640\n",
      "0 /500\n",
      "Time taken: 5.47 seconds\n",
      "9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:espnet.nets.beam_search:best hypo length: 9 == max output length: 9\n",
      "2023-12-11 18:13:25,465 WARNING [beam_search.py:476] best hypo length: 9 == max output length: 9\n",
      "2023-12-11 18:13:25,465 WARNING [beam_search.py:476] best hypo length: 9 == max output length: 9\n",
      "2023-12-11 18:13:25,465 WARNING [beam_search.py:476] best hypo length: 9 == max output length: 9\n",
      "2023-12-11 18:13:25,465 WARNING [beam_search.py:476] best hypo length: 9 == max output length: 9\n",
      "2023-12-11 18:13:25,465 WARNING [beam_search.py:476] best hypo length: 9 == max output length: 9\n",
      "2023-12-11 18:13:25,465 WARNING [beam_search.py:476] best hypo length: 9 == max output length: 9\n",
      "2023-12-11 18:13:25,465 WARNING [beam_search.py:476] best hypo length: 9 == max output length: 9\n",
      "2023-12-11 18:13:25,465 WARNING [beam_search.py:476] best hypo length: 9 == max output length: 9\n",
      "2023-12-11 18:13:25,465 WARNING [beam_search.py:476] best hypo length: 9 == max output length: 9\n",
      "2023-12-11 18:13:25,465 WARNING [beam_search.py:476] best hypo length: 9 == max output length: 9\n",
      "2023-12-11 18:13:25,465 WARNING [beam_search.py:476] best hypo length: 9 == max output length: 9\n",
      "2023-12-11 18:13:25,465 WARNING [beam_search.py:476] best hypo length: 9 == max output length: 9\n",
      "2023-12-11 18:13:25,465 WARNING [beam_search.py:476] best hypo length: 9 == max output length: 9\n",
      "WARNING:espnet.nets.beam_search:decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:13:25,468 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:13:25,468 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:13:25,468 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:13:25,468 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:13:25,468 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:13:25,468 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:13:25,468 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:13:25,468 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:13:25,468 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:13:25,468 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:13:25,468 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:13:25,468 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:13:25,468 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 /500\n",
      "Time taken: 3.11 seconds\n",
      "15200\n",
      "2 /500\n",
      "Time taken: 4.67 seconds\n",
      "11040\n",
      "3 /500\n",
      "Time taken: 3.13 seconds\n",
      "23840\n",
      "4 /500\n",
      "Time taken: 5.49 seconds\n",
      "39040\n",
      "5 /500\n",
      "Time taken: 6.20 seconds\n",
      "23360\n",
      "6 /500\n",
      "Time taken: 7.02 seconds\n",
      "9920\n",
      "7 /500\n",
      "Time taken: 2.81 seconds\n",
      "17120\n",
      "8 /500\n",
      "Time taken: 5.09 seconds\n",
      "36000\n",
      "9 /500\n",
      "Time taken: 5.24 seconds\n",
      "72800\n",
      "10 /500\n",
      "Time taken: 8.48 seconds\n",
      "56320\n",
      "11 /500\n",
      "Time taken: 9.73 seconds\n",
      "20800\n",
      "12 /500\n",
      "Time taken: 6.20 seconds\n",
      "14240\n",
      "13 /500\n",
      "Time taken: 4.76 seconds\n",
      "53920\n",
      "14 /500\n",
      "Time taken: 7.27 seconds\n",
      "26400\n",
      "15 /500\n",
      "Time taken: 4.19 seconds\n",
      "27680\n",
      "16 /500\n",
      "Time taken: 4.84 seconds\n",
      "31200\n",
      "17 /500\n",
      "Time taken: 5.40 seconds\n",
      "13600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suryansh/anaconda3/lib/python3.11/site-packages/espnet/nets/ctc_prefix_score.py:323: RuntimeWarning: invalid value encountered in logaddexp\n",
      "  r_sum = self.xp.logaddexp(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 /500\n",
      "Time taken: 4.23 seconds\n",
      "43680\n",
      "19 /500\n",
      "Time taken: 7.41 seconds\n",
      "36960\n",
      "20 /500\n",
      "Time taken: 7.15 seconds\n",
      "19040\n",
      "21 /500\n",
      "Time taken: 5.89 seconds\n",
      "37120\n",
      "22 /500\n",
      "Time taken: 10.08 seconds\n",
      "27840\n",
      "23 /500\n",
      "Time taken: 10.98 seconds\n",
      "22880\n",
      "24 /500\n",
      "Time taken: 5.62 seconds\n",
      "73280\n",
      "25 /500\n",
      "Time taken: 11.30 seconds\n",
      "8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:espnet.nets.beam_search:best hypo length: 8 == max output length: 8\n",
      "2023-12-11 18:16:01,439 WARNING [beam_search.py:476] best hypo length: 8 == max output length: 8\n",
      "2023-12-11 18:16:01,439 WARNING [beam_search.py:476] best hypo length: 8 == max output length: 8\n",
      "2023-12-11 18:16:01,439 WARNING [beam_search.py:476] best hypo length: 8 == max output length: 8\n",
      "2023-12-11 18:16:01,439 WARNING [beam_search.py:476] best hypo length: 8 == max output length: 8\n",
      "2023-12-11 18:16:01,439 WARNING [beam_search.py:476] best hypo length: 8 == max output length: 8\n",
      "2023-12-11 18:16:01,439 WARNING [beam_search.py:476] best hypo length: 8 == max output length: 8\n",
      "2023-12-11 18:16:01,439 WARNING [beam_search.py:476] best hypo length: 8 == max output length: 8\n",
      "2023-12-11 18:16:01,439 WARNING [beam_search.py:476] best hypo length: 8 == max output length: 8\n",
      "2023-12-11 18:16:01,439 WARNING [beam_search.py:476] best hypo length: 8 == max output length: 8\n",
      "2023-12-11 18:16:01,439 WARNING [beam_search.py:476] best hypo length: 8 == max output length: 8\n",
      "2023-12-11 18:16:01,439 WARNING [beam_search.py:476] best hypo length: 8 == max output length: 8\n",
      "2023-12-11 18:16:01,439 WARNING [beam_search.py:476] best hypo length: 8 == max output length: 8\n",
      "2023-12-11 18:16:01,439 WARNING [beam_search.py:476] best hypo length: 8 == max output length: 8\n",
      "WARNING:espnet.nets.beam_search:decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:16:01,442 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:16:01,442 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:16:01,442 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:16:01,442 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:16:01,442 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:16:01,442 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:16:01,442 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:16:01,442 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:16:01,442 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:16:01,442 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:16:01,442 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:16:01,442 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n",
      "2023-12-11 18:16:01,442 WARNING [beam_search.py:481] decoding may be stopped by the max output length limitation, please consider to increase the maxlenratio.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 /500\n",
      "Time taken: 2.76 seconds\n",
      "16800\n",
      "27 /500\n",
      "Time taken: 4.41 seconds\n",
      "21600\n",
      "28 /500\n",
      "Time taken: 5.67 seconds\n",
      "13120\n",
      "29 /500\n",
      "Time taken: 3.82 seconds\n",
      "71200\n",
      "30 /500\n",
      "Time taken: 10.80 seconds\n",
      "19520\n",
      "31 /500\n",
      "Time taken: 7.45 seconds\n",
      "12320\n",
      "32 /500\n",
      "Time taken: 4.32 seconds\n",
      "17600\n",
      "33 /500\n",
      "Time taken: 5.22 seconds\n",
      "16480\n",
      "34 /500\n",
      "Time taken: 4.97 seconds\n",
      "38400\n",
      "35 /500\n",
      "Time taken: 6.48 seconds\n",
      "26560\n",
      "36 /500\n",
      "Time taken: 6.33 seconds\n",
      "38560\n",
      "37 /500\n",
      "Time taken: 6.53 seconds\n",
      "32000\n",
      "38 /500\n",
      "Time taken: 8.95 seconds\n",
      "31360\n",
      "39 /500\n",
      "Time taken: 8.91 seconds\n",
      "22720\n",
      "40 /500\n",
      "Time taken: 8.98 seconds\n",
      "74400\n",
      "41 /500\n",
      "Time taken: 9.56 seconds\n",
      "43200\n",
      "42 /500\n",
      "Time taken: 6.77 seconds\n",
      "14880\n",
      "43 /500\n",
      "Time taken: 5.06 seconds\n",
      "14880\n",
      "44 /500\n",
      "Time taken: 5.72 seconds\n",
      "28160\n",
      "45 /500\n",
      "Time taken: 5.01 seconds\n",
      "16320\n",
      "46 /500\n",
      "Time taken: 5.41 seconds\n",
      "18880\n",
      "47 /500\n",
      "Time taken: 5.96 seconds\n",
      "22080\n",
      "48 /500\n",
      "Time taken: 7.23 seconds\n",
      "9920\n",
      "49 /500\n",
      "Time taken: 2.65 seconds\n",
      "61280\n",
      "50 /500\n",
      "Time taken: 5.94 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import librosa.display\n",
    "from IPython.display import display, Audio\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "col_names = ['path', 'text', 'time', 'sr']\n",
    "preds = \"\"\n",
    "target = \"\"\n",
    "\n",
    "for i, chunk in enumerate(chunks_array):\n",
    "    start_time = time.time()\n",
    "    speech = np.array([])\n",
    "    duration=split_sec['end'][i]*1000-split_sec['start'][i] * 1000\n",
    "    for _, row in df.iterrows():\n",
    "        start_sample = row['start']-split_sec['start'][i] * 1000\n",
    "        end_sample = row['end']-split_sec['start'][i] * 1000\n",
    "#         print(start_sample, end_sample, duration)\n",
    "        if(start_sample<0 and end_sample<0):\n",
    "            continue\n",
    "        if(start_sample>duration and end_sample>duration):\n",
    "            continue\n",
    "#         print(\"Y\")\n",
    "        speech = np.concatenate([speech, chunk[int(max(0,start_sample))*16:int(min(duration, end_sample))*16]])\n",
    "\n",
    "    print(len(speech))\n",
    "    \n",
    "    if len(speech) != 0:\n",
    "        nbests = speech2text(speech)\n",
    "        text, *_ = nbests[0]\n",
    "#         output_filename = f'results/output_chunk{i}.wav'\n",
    "#         sf.write(output_filename, speech, samplerate=16000)\n",
    "        if(preds==\"\"):\n",
    "            preds=(text_normalizer(text))\n",
    "        else:\n",
    "            preds += \" \" + (text_normalizer(text))\n",
    "\n",
    "    print(i, \"/500\")\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Time taken: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a944f2",
   "metadata": {},
   "source": [
    "she was tired of other things she tried this morning an air or two upon the piano sang a simple song in a sweet but slightly metallic voice and then seating herself by the open window read philips letter well mother said the young student looking up with a shade of impatience i hope thee told the elders that father and i are responsible for the piano and that much as thee loves music thee is never in the room when it is played i heard father tell cousin abner that he was whipped so often for whistling when he was a boy that he was determined to have what compensation he could get now thy ways greatly try me ruth and all thy relations is thy father willing thee should go away to a school of the worlds people i have not asked him ruth replied with a look that might imply that she was one of those determined little bodies who first made up her own mind and then compelled others to make up theirs in accordance with hers mother im going to study medicine margaret bolton almost lost for a moment her habitual placidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "76d7a916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE CHIEF WEVE SEEN THAT WEVE SO ID SAY THIRD OF OTHER THINGS SHE TRIED THIS MORNING AND ERIC WERE GOING TO  ILL TALK TO YOU ABOUT SO THATS THE FROM THE PNL AND STAYING A SIMPLE SONG AND ITS SWEET BUT SLIGHTLY METALLIC VOIDS AND THEN YOURSELVES BY THE OPEN WINDOW RED PHILIPS PLATTER WELL THE IS THERE  ARE THERE ANY SO THE YOUNG STUDENT LOOKING AT  WITH THE SHADOW IN PATIENTS I HOPE YOU TOLD US ELDERS THAT FATHER AND I ARE RESPONSIBLE FOR THE AND ID LIKE TO KNOW AND THAT MUCH OF THE LLOYDS MUSIC IS NEVER IN THE ROOM WHEN IT IS PLAYED I HEARD FATHER TELKONES AND AVENUE THAT HES WITH WHITBREAD SO ILL START WITH AND FOR WHISTLELING WHEN HE WAS A BOY THAT HE WAS DETERMINED TO HAVE WHAT COMPENSATION HE COULD GET NOW ID LIKE TO TURN THE SO THATS THE ITS GREAT FOR US STATEMENTS MADE BY MANAGEMENT ITS TRIMMING ROOTS AND ALL THATS  IM NOT FATHER WITH SO IT WAS I THINK THEYRE GOING TO BE IT SHOULD GO THE WAY TO A SCHOOL OF THE WORLDS PEOPLE I HAVE NOT ASKED HIM REREPLIED WITH A LOOK THAT MIGHT SIMPLY THAT SHES WAS ONE OF THOSE DETERMINANTS IN THE MIDDLE BODIES WEVE ALSO MADE UP OUR OWN MINES AND THEN COMPELLED OTHERS TO THEIRS IN ACCORDANCE WITH THEIRS MOTHERS IM NOT SURE IM GOING TO STUDY MEDICINES AND THATS WHAT WERE GOING TO DO GRID BALTIN ALMOST WHATS THE CUSTOMER SO FOR A MOMENT OR A BIT OF A POSSIBILITY\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1f7d08f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER: tensor(7.4393)\n",
      "WER: tensor(7.9091)\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.text import CharErrorRate, WordErrorRate\n",
    "target=\"she tried this morning an air or two upon the piano sang a simple song in a sweet but slightly metallic voice and then seating herself by the open window read philips letter\"\n",
    "cer = CharErrorRate()\n",
    "print(\"CER:\", cer(preds, target))\n",
    "wer = WordErrorRate()\n",
    "print(\"WER:\", wer(preds, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2be87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
